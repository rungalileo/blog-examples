{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -okenizers (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -romptgalileo (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -vicorn (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -okenizers (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -romptgalileo (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -vicorn (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install pymilvus llama-index python-dotenv openai transformers -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "zilliz_uri = os.getenv(\"ZILLIZ_URI\")\n",
    "zilliz_token = os.getenv(\"ZILLIZ_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import VectorStoreIndex, StorageContext, ServiceContext, set_global_service_context\n",
    "from llama_index.callbacks import CallbackManager, TokenCountingHandler\n",
    "from llama_index.vector_stores import MilvusVectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "token_counter = TokenCountingHandler(\n",
    "    tokenizer=tiktoken.encoding_for_model(\"gpt-3.5-turbo\").encode\n",
    ")\n",
    "\n",
    "callback_manager = CallbackManager([token_counter])\n",
    "\n",
    "# llm = Anthropic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings import HuggingFaceEmbedding\n",
    "\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"sentence-transformers/all-MiniLM-L12-v2\")\n",
    "# service_context = ServiceContext.from_defaults(embed_model=embed_model)\n",
    "\n",
    "service_context = ServiceContext.from_defaults(\n",
    "    callback_manager=callback_manager, embed_model=embed_model\n",
    ")\n",
    "\n",
    "# set the global default!\n",
    "# set_global_service_context(service_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:pymilvus.milvus_client.milvus_client:Created new connection using: 1063adc3165445508287c68e6a72cfe8\n"
     ]
    }
   ],
   "source": [
    "vdb = MilvusVectorStore(\n",
    "    uri = zilliz_uri,\n",
    "    token = zilliz_token,\n",
    "    collection_name = \"tds_articles\",\n",
    "    similarity_metric = \"L2\",\n",
    "    text_key=\"paragraph\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store = StorageContext.from_defaults(vector_store=vdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_index = VectorStoreIndex.from_vector_store(vector_store=vdb, service_context=service_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = vector_index.as_query_engine(similarity_top_k=5)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(response='Deep learning is a type of machine learning that involves training artificial neural networks with multiple layers. It is known for its ability to automatically learn and extract complex patterns and features from large amounts of data. Deep learning has been successful in various applications such as image and speech recognition, natural language processing, and autonomous driving.', source_nodes=[NodeWithScore(node=TextNode(id_='9211801e-ee38-4728-927f-d4d1ed6ebd5d', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='eb3e39b94ea1bf63bfe68391ab213af2183439e6028850bb92e00ad92c412d62', text='\\u200c', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=24.830387115478516), NodeWithScore(node=TextNode(id_='6f74e688-c0c7-4998-aee7-fde0a6a9a8ac', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='4daaf8bbf838e64a279b08da20e4bb1ea9bf2be29e2009b680df0a69fd56f939', text='\\u200c\\u200c', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=24.830387115478516), NodeWithScore(node=TextNode(id_='ba209d02-ab56-4744-809f-25c9f51c3b45', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='5bb5a58fff19982a0c1fac2aea10337d7ca9a24b97445cce70041f4eab0fc856', text='\\u200d', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=24.830387115478516), NodeWithScore(node=TextNode(id_='5cc4e3cb-9ad3-4f5c-8fd3-10f600d8ac7d', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='b77b316600cd103a2ceacea7b163db4250378fb88fde11021350f99f9a935c63', text='(8)Lin, H.W., Tegmark, M. & Rolnick, D. Why Does Deep and Cheap Learning Work So Well?. J Stat Phys 168, 1223–1247 (2017). https://doi.org/10.1007/s10955-017-1836-5', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=24.98073959350586), NodeWithScore(node=TextNode(id_='0c1f9399-0516-4568-a728-ceff17314e93', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='a536d058b4470f5efc4728b512dd3a932616cc3070d7cf48cd17b0347af543ad', text='InceptionNet', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=25.010150909423828)], metadata={'9211801e-ee38-4728-927f-d4d1ed6ebd5d': {}, '6f74e688-c0c7-4998-aee7-fde0a6a9a8ac': {}, 'ba209d02-ab56-4744-809f-25c9f51c3b45': {}, '5cc4e3cb-9ad3-4f5c-8fd3-10f600d8ac7d': {}, '0c1f9399-0516-4568-a728-ceff17314e93': {}})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What is a deep learning?\"\n",
    "res = query_engine.query(query)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system: You are an expert Q&A system that is trusted around the world.\n",
      "Always answer the query using the provided context information, and not prior knowledge.\n",
      "Some rules to follow:\n",
      "1. Never directly reference the given context in your answer.\n",
      "2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.\n",
      "user: Context information is below.\n",
      "---------------------\n",
      "‌\n",
      "\n",
      "‌‌\n",
      "\n",
      "‍\n",
      "\n",
      "(8)Lin, H.W., Tegmark, M. & Rolnick, D. Why Does Deep and Cheap Learning Work So Well?. J Stat Phys 168, 1223–1247 (2017). https://doi.org/10.1007/s10955-017-1836-5\n",
      "\n",
      "InceptionNet\n",
      "---------------------\n",
      "Given the context information and not prior knowledge, answer the query.\n",
      "Query: What is a deep learning?\n",
      "Answer: \n"
     ]
    }
   ],
   "source": [
    "print(token_counter.llm_token_counts[1].prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'assistant: A large language model is a type of model that has the ability to perform a wide range of tasks involving language processing. These models have shown significant advancements in their capabilities, which are primarily attributed to increased computational resources and the repetition of simple operations at scale. They have evolved from being limited to narrow applications to now being able to engage in fluent, multi-turn conversations.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " token_counter.llm_token_counts[0].completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = list(res.metadata.keys())\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:pymilvus.milvus_client.milvus_client:Created new connection using: cf0dddc733e940ff979bd6fd499ed475\n"
     ]
    }
   ],
   "source": [
    "from pymilvus import MilvusClient\n",
    "\n",
    "client = MilvusClient(\n",
    "uri=zilliz_uri,\n",
    "token=zilliz_token,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'paragraph': 'Note that the ANOVA requires some assumptions (i.e., independence, equality of variances and normality). The aim of this post is to illustrate how to do an ANOVA by hand and not how to verify these assumptions, so we suppose they are met without any verification. See how to test these assumptions in R if you are interested.',\n",
       "  'id': 'https://towardsdatascience.com/how-to-one-way-anova-by-hand-4c19e2a61a8c+6'}]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.get(\n",
    "    collection_name=\"tds_articles\",\n",
    "    ids='https://towardsdatascience.com/how-to-one-way-anova-by-hand-4c19e2a61a8c+6',\n",
    "    output_fields=[\"paragraph\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!python -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
