{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic data with GPT-4o and OpenAI Batch service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random, json, yaml, random\n",
    "from string import Template\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from fortune_500 import companies\n",
    "\n",
    "load_dotenv(\"../.env\")\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Task Overview**\n",
      "Your job is to create structured data in a specific format (YAML) that includes:\n",
      "\n",
      "1. **Context:** This should be a collection of at least 10 paragraphs from quarterly and yearly reports of various companies in the S&P 500 list. The paragraphs can vary in length (10-15 sentences) and should contain both text and a table in markdown format with at least *10* rows and *5* columns. The table should be present in just one paragraph. The context should be rich enough to allow for detailed questions and answers. Talk about competitors in the context. Be creative while creating the context and questions so that it is different every time. \n",
      "\n",
      "2. **Questions:** You need to create a list of complex questions based on the context. These questions should require deep reasoning, involve multiple references, or be based on the information in the table. Include questions for each of these types:\n",
      "- reasoning: questions that require synthesizing information from multiple paragraphs.\n",
      "- cannot answer: questions that cannot be answered with the provided context. Say \"I do not have the information to answer this question.\"\n",
      "- tabular: questions that specifically ask for information from the table. Generate 3 questions which require different operations.\n",
      "- extractive: questions that require extracting specific entities from the context.\n",
      "- math: questions that involve different type of relevant math calculations.\n",
      "\n",
      "3. **Answers:** Provide a concise answer based on the context for each question. If a question cannot be answered with the given information, state that you do not have the information. For math questions, show the calculations used to arrive at the answer.\n",
      "\n",
      "# Schema of yaml output\n",
      "Sector: Information Technology\n",
      "Company: Monolithic Power Systems\n",
      "Context: List[str] \n",
      "Questions : List[Tuple[type: str, question: str]] \n",
      "Answers: List[str]\n",
      "\n",
      "Don't generate anything after generating the YAML output.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI()\n",
    "\n",
    "sector, company_name = random.choice(companies)\n",
    "\n",
    "MODEL = \"gpt-4o-2024-08-06\"\n",
    "SYSTEM = \"You are an expert in data annotation for machine learning models, specifically in the areas of LLM and generative AI.\"\n",
    "\n",
    "PROMPT = Template(\"\"\"**Task Overview**\n",
    "Your job is to create structured data in a specific format (YAML) that includes:\n",
    "\n",
    "1. **Context:** This should be a collection of at least 10 paragraphs from quarterly and yearly reports of various companies in the S&P 500 list. The paragraphs can vary in length (10-15 sentences) and should contain both text and a table in markdown format with at least *10* rows and *5* columns. The table should be present in just one paragraph. The context should be rich enough to allow for detailed questions and answers. Talk about competitors in the context. Be creative while creating the context and questions so that it is different every time. \n",
    "\n",
    "2. **Questions:** You need to create a list of complex questions based on the context. These questions should require deep reasoning, involve multiple references, or be based on the information in the table. Include questions for each of these types:\n",
    "- reasoning: questions that require synthesizing information from multiple paragraphs.\n",
    "- cannot answer: questions that cannot be answered with the provided context. Say \"I do not have the information to answer this question.\"\n",
    "- tabular: questions that specifically ask for information from the table. Generate 3 questions which require different operations.\n",
    "- extractive: questions that require extracting specific entities from the context.\n",
    "- math: questions that involve different type of relevant math calculations.\n",
    "\n",
    "3. **Answers:** Provide a concise answer based on the context for each question. If a question cannot be answered with the given information, state that you do not have the information. For math questions, show the calculations used to arrive at the answer.\n",
    "\n",
    "# Schema of yaml output\n",
    "Sector: $sector\n",
    "Company: $company_name\n",
    "Context: List[str] \n",
    "Questions : List[Tuple[type: str, question: str]] \n",
    "Answers: List[str]\n",
    "\n",
    "Don't generate anything after generating the YAML output.\n",
    "\"\"\")\n",
    "\n",
    "print(PROMPT.substitute({'sector' : sector, 'company_name' : company_name}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(sector, company_name, system, prompt, model):\n",
    "    return client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=[\n",
    "        {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": [\n",
    "            {\n",
    "            \"text\": system,\n",
    "            \"type\": \"text\"\n",
    "            }\n",
    "        ]\n",
    "        },\n",
    "        {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "            \"text\": prompt,\n",
    "            \"type\": \"text\"\n",
    "            }\n",
    "        ]\n",
    "        }\n",
    "    ],\n",
    "    temperature=1.0,\n",
    "    max_tokens=4000,\n",
    "    top_p=1,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0,\n",
    "    response_format={\n",
    "        \"type\": \"text\"\n",
    "    }\n",
    "    )\n",
    "\n",
    "input = PROMPT.substitute({'sector' : sector, 'company_name' : company_name})\n",
    "response = get_data(*random.choice(companies), SYSTEM, input, model=MODEL)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create batches for generating synthetic data with GPT-4o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a file with requests\n",
    "file_path = \"../data/syn_data_rag/input/data.jsonl\"\n",
    "print(file_path)\n",
    "with open(file_path, \"w+\") as f:\n",
    "    for i in range(2000):\n",
    "        sector, company_name = random.choice(companies)\n",
    "        input = {\"custom_id\": str(i), \n",
    "                \"method\": \"POST\", \"url\": \"/v1/chat/completions\", \n",
    "                \"body\": {\"model\": MODEL, \n",
    "                        \"messages\": [{\"role\": \"system\", \"content\": SYSTEM},\n",
    "                                    {\"role\": \"user\", \"content\": PROMPT.substitute({'sector' : sector, 'company_name' : company_name})}],\n",
    "                        \"max_tokens\": 5000,\n",
    "                        \"temperature\": 1.0,}}\n",
    "        f.write(json.dumps(input))\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "# Upload the file to OpenAI            \n",
    "batch_input_file_id = client.files.create(\n",
    "file=open(file_path, \"rb\"),\n",
    "purpose=\"batch\"\n",
    ").id\n",
    "\n",
    "# Create a batch\n",
    "client.batches.create(\n",
    "    input_file_id=batch_input_file_id,\n",
    "    endpoint=\"/v1/chat/completions\",\n",
    "    completion_window=\"24h\",\n",
    "    metadata={\n",
    "    \"description\": f\"synthetic data {i}\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_response = client.files.content(client.batches.list(limit=1).data[0].output_file_id)\n",
    "with open(\"../data/syn_data_rag/output/test.jsonl\", \"w+\") as f:\n",
    "    f.write(file_response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create prompts and responses using the prompt and outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output schema validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from pydantic import BaseModel, ValidationError\n",
    "\n",
    "class Question(BaseModel):\n",
    "    type: str\n",
    "    question: str\n",
    "\n",
    "class Schema(BaseModel):\n",
    "    Sector: str\n",
    "    Company: str\n",
    "    Context: List[str]\n",
    "    Questions: List[Question]\n",
    "    Answers: List[str]\n",
    "\n",
    "def validate_dict(data: dict) -> bool:\n",
    "    try:\n",
    "        validated_data = Schema(**data)\n",
    "        return True\n",
    "    except ValidationError as e:\n",
    "        # print(e.json())\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14018\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sector</th>\n",
       "      <th>context</th>\n",
       "      <th>question_type</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Financials</td>\n",
       "      <td>\\n1. Moody's risk assessment division has play...</td>\n",
       "      <td>reasoning</td>\n",
       "      <td>How has Moody's Corporation leveraged its geog...</td>\n",
       "      <td>Moody's has focused its geographical expansion...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Financials</td>\n",
       "      <td>\\n1. Moody's internal forecasts suggest contin...</td>\n",
       "      <td>cannot answer</td>\n",
       "      <td>What are the CEO's personal views on the curre...</td>\n",
       "      <td>I do not have the information to answer this q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Financials</td>\n",
       "      <td>\\n1. Moody's internal forecasts suggest contin...</td>\n",
       "      <td>tabular</td>\n",
       "      <td>What is the year-over-year growth percentage i...</td>\n",
       "      <td>15.38%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Financials</td>\n",
       "      <td>\\n1. In terms of financial performance, Moody'...</td>\n",
       "      <td>tabular</td>\n",
       "      <td>Based on the table, which metric showed a nega...</td>\n",
       "      <td>The Equity Ratio showed a negative growth from...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Financials</td>\n",
       "      <td>\\n1. During the annual shareholders' meeting, ...</td>\n",
       "      <td>tabular</td>\n",
       "      <td>Calculate the average Earnings per Share for Q...</td>\n",
       "      <td>The average Earnings per Share for Q1 and Q2 o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sector                                            context  \\\n",
       "0  Financials  \\n1. Moody's risk assessment division has play...   \n",
       "1  Financials  \\n1. Moody's internal forecasts suggest contin...   \n",
       "2  Financials  \\n1. Moody's internal forecasts suggest contin...   \n",
       "3  Financials  \\n1. In terms of financial performance, Moody'...   \n",
       "4  Financials  \\n1. During the annual shareholders' meeting, ...   \n",
       "\n",
       "   question_type                                           question  \\\n",
       "0      reasoning  How has Moody's Corporation leveraged its geog...   \n",
       "1  cannot answer  What are the CEO's personal views on the curre...   \n",
       "2        tabular  What is the year-over-year growth percentage i...   \n",
       "3        tabular  Based on the table, which metric showed a nega...   \n",
       "4        tabular  Calculate the average Earnings per Share for Q...   \n",
       "\n",
       "                                              answer  \n",
       "0  Moody's has focused its geographical expansion...  \n",
       "1  I do not have the information to answer this q...  \n",
       "2                                             15.38%  \n",
       "3  The Equity Ratio showed a negative growth from...  \n",
       "4  The average Earnings per Share for Q1 and Q2 o...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# format the context\n",
    "def get_context_for_prompt(x):\n",
    "    context = ''\n",
    "    for i, p in enumerate(x):\n",
    "        context += f\"\\n{i+1}. {p}\"\n",
    "    return context\n",
    "\n",
    "# read the file\n",
    "with open(\"../data/syn_data_rag/output/data.jsonl\", \"r\") as f:\n",
    "    data = f.readlines()\n",
    "\n",
    "# parse the data\n",
    "data_formatted = []\n",
    "for line in data:\n",
    "    d = json.loads(line)['response']['body']['choices'][0]['message']['content'].replace(\"```yaml\\n\", \"\").replace(\"\\n```\", \"\")\n",
    "    try:\n",
    "        d = yaml.load(d, Loader=yaml.FullLoader)\n",
    "        if validate_dict(d):\n",
    "            for question, answer in zip(d['Questions'], d['Answers']):\n",
    "                random.shuffle(d['Context']) # shuffle every time to create variability\n",
    "                context = get_context_for_prompt(d['Context'])\n",
    "                data_formatted.append((d['Sector'], context,  question['type'], question['question'], answer))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# create a dataframe\n",
    "df = pd.DataFrame(data_formatted, columns=['sector', 'context', 'question_type', 'question', 'answer'])\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "question_type\n",
       "tabular          4688\n",
       "math             3163\n",
       "extractive       2812\n",
       "reasoning        1739\n",
       "cannot answer    1587\n",
       "cannot_answer      29\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.question_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sector\n",
       "Information Technology    2213\n",
       "Health Care               1762\n",
       "Financials                1754\n",
       "Consumer Discretionary    1667\n",
       "Industrials               1627\n",
       "Consumer Staples          1165\n",
       "Real Estate                973\n",
       "Technology                 780\n",
       "Materials                  616\n",
       "Communication Services     614\n",
       "Energy                     415\n",
       "Utilities                  397\n",
       "Healthcare                  26\n",
       "Telecommunications           9\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sector.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(\"../data/syn_data_rag/extracted/data.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "v2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
