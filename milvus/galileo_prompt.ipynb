{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import openai\n",
    "import promptquality as pq\n",
    "import pandas as pd\n",
    "from pymilvus import connections, Collection\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "zilliz_uri = os.getenv(\"ZILLIZ_URI\")\n",
    "zilliz_token = os.getenv(\"ZILLIZ_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "connections.connect(uri=zilliz_uri, token=zilliz_token)\n",
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L12-v2\")\n",
    "collection = Collection(name=\"tds_articles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>context</th>\n",
       "      <th>context_embedding</th>\n",
       "      <th>query_embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explain vector embeddings to me</td>\n",
       "      <td>Embedding (also called Vector Embeddings) is a...</td>\n",
       "      <td>[0.016721306, -0.07329102, 0.04982487, -0.0250...</td>\n",
       "      <td>[0.009870021, -0.09072343, -0.025687167, -0.06...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the best phone to buy?</td>\n",
       "      <td>The advantages of Moto:\\n\\nMobileNet\\n\\nThe mo...</td>\n",
       "      <td>[-0.031568494, 0.078815974, 0.047155913, 0.049...</td>\n",
       "      <td>[-0.06841213, 0.057167217, 0.030635849, -0.002...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is machine learning?</td>\n",
       "      <td>Machine Learning (ML), a technique in which ma...</td>\n",
       "      <td>[-0.03973866, -0.061922736, -0.09700069, -0.01...</td>\n",
       "      <td>[-0.019182485, -0.024332881, -0.047722008, -0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             query  \\\n",
       "0  Explain vector embeddings to me   \n",
       "1   What is the best phone to buy?   \n",
       "2        What is machine learning?   \n",
       "\n",
       "                                             context  \\\n",
       "0  Embedding (also called Vector Embeddings) is a...   \n",
       "1  The advantages of Moto:\\n\\nMobileNet\\n\\nThe mo...   \n",
       "2  Machine Learning (ML), a technique in which ma...   \n",
       "\n",
       "                                   context_embedding  \\\n",
       "0  [0.016721306, -0.07329102, 0.04982487, -0.0250...   \n",
       "1  [-0.031568494, 0.078815974, 0.047155913, 0.049...   \n",
       "2  [-0.03973866, -0.061922736, -0.09700069, -0.01...   \n",
       "\n",
       "                                     query_embedding  \n",
       "0  [0.009870021, -0.09072343, -0.025687167, -0.06...  \n",
       "1  [-0.06841213, 0.057167217, 0.030635849, -0.002...  \n",
       "2  [-0.019182485, -0.024332881, -0.047722008, -0....  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_context(query, similarity_top_k=10):\n",
    "  query_embedding = model.encode(query)\n",
    "  closest = collection.search([query_embedding],\n",
    "                    anns_field='embedding', \n",
    "                      param={\"metric_type\": \"L2\",\n",
    "                              \"params\": {\"nprobe\": 16}}, \n",
    "                      limit=5,\n",
    "                      output_fields=[\"paragraph\"])\n",
    "\n",
    "  contexts = [c.entity.get(\"paragraph\") for c in closest[0]]\n",
    "  context_string = \"\\n\\n\".join(contexts)\n",
    "  context_embedding = model.encode(context_string)\n",
    "  return context_string, context_embedding, query_embedding\n",
    "\n",
    "# Each 'query' represents a user query we'd like the model to answer using context from a vector DB.\n",
    "# It could also contain a 'target' column for BLEU and ROUGE computation.\n",
    "# \"What is the capital of France?\", \"What is the capital of Germany?\", \n",
    "\n",
    "queries = [\"Explain vector embeddings to me\", \"What is the best phone to buy?\", \n",
    "           \"What is machine learning?\"]\n",
    "\n",
    "contexts, context_embeddings, query_embeddings = [], [], []\n",
    "for query in queries:\n",
    "  context, context_embedding, query_embedding = get_context(query)\n",
    "  contexts.append(context)\n",
    "  context_embeddings.append(context_embedding)\n",
    "  query_embeddings.append(query_embedding)\n",
    "\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df[\"query\"] = queries\n",
    "df[\"context\"] = contexts\n",
    "df[\"context_embedding\"] = context_embeddings\n",
    "df[\"query_embedding\"] = query_embeddings\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose the metrics you'd like to run and create any of your own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from promptquality import Scorers, SupportedModels\n",
    "\n",
    "metrics = [\n",
    "    Scorers.groundedness,\n",
    "    Scorers.context_relevance,\n",
    "    # Uncertainty, BLEU, and ROUGE are automatically included\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define your template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"You are an expert Q&A system that is trusted around the world.\n",
    "Always answer the query using the provided context information, and not prior knowledge.\n",
    "Some rules to follow:\n",
    "1. Never directly reference the given context in your answer.\n",
    "2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.\n",
    "\n",
    "Context information is below.\n",
    "---------------------\n",
    "{context}\n",
    "---------------------\n",
    "Given the context information and not prior knowledge, answer the query.\n",
    "Query: {query}\n",
    "Answer: \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run your prompts and evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pq.login(\"https://console.sandbox.rungalileo.io\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt run complete!: : 8it [00:09,  1.21s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”­ View your prompt run on the Galileo console at: https://console.sandbox.rungalileo.io/prompt-evaluation/prompts?projectId=529569d3-6d13-4516-8622-a74c178bd2f5&runId=17b0ae8d-a3c7-4a9e-a5da-defc502296da&taskType=7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PromptMetrics(total_responses=3, average_hallucination=0.35911368989061826, average_bleu=None, average_rouge=None, average_cost=0.0019920000000000003, total_cost=0.005976)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pq.run(project_name='rag_demo_10_11',\n",
    "       template=template,\n",
    "       dataset=df.to_dict(orient=\"records\"),\n",
    "       scorers=metrics,\n",
    "       settings=pq.Settings(model_alias=SupportedModels.chat_gpt_16k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
